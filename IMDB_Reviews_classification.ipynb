{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/andrefuentes/Desktop/Python_Project/imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261391"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'review', 'movie_title', 'tconst', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>review</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>tconst</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Heres a perfect example of the pitfalls of wr...</td>\n",
       "      <td>Carmencita (Short 1894)</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"This film is part of the series of short Edis...</td>\n",
       "      <td>Carmencita (Short 1894)</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Objectively, theres nothing really WRONG with...</td>\n",
       "      <td>Carmencita (Short 1894)</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"This is the first movie in what quickly becam...</td>\n",
       "      <td>Carmencita (Short 1894)</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Watching a film like this, it becomes fairly ...</td>\n",
       "      <td>Carmencita (Short 1894)</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id                                             review  \\\n",
       "0          1  \"Heres a perfect example of the pitfalls of wr...   \n",
       "1          2  \"This film is part of the series of short Edis...   \n",
       "2          3  \"Objectively, theres nothing really WRONG with...   \n",
       "3          4  \"This is the first movie in what quickly becam...   \n",
       "4          5  \"Watching a film like this, it becomes fairly ...   \n",
       "\n",
       "               movie_title     tconst  rating  \n",
       "0  Carmencita (Short 1894)  tt0000001     NaN  \n",
       "1  Carmencita (Short 1894)  tt0000001     NaN  \n",
       "2  Carmencita (Short 1894)  tt0000001     NaN  \n",
       "3  Carmencita (Short 1894)  tt0000001     NaN  \n",
       "4  Carmencita (Short 1894)  tt0000001     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract movie type and year out of movie_title\n",
    "\n",
    "data[['title', 'kind_of_movie', 'year']] = data['movie_title'].str.extract(r'^(.*?) \\((.*?) (\\d{4})\\)$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={'tconst': 'movie_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['movie_title', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'review', 'movie_id', 'title', 'kind_of_movie', 'year'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['title', 'kind_of_movie', 'year','review','movie_id','review_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Alice in Wonderland        67\n",
       "A Christmas Carol          58\n",
       "The Wind in the Willows    48\n",
       "Rebecca                    43\n",
       "Oliver Twist               42\n",
       "                           ..\n",
       "A Small Town Princess       1\n",
       "Retik the Moon Menace       1\n",
       "Satan's Storybook           1\n",
       "Roe vs. Wade                1\n",
       "The 3,000 Mile Chase        1\n",
       "Name: title, Length: 7130, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of reviews per\n",
    "review_distribution = data.groupby('review_id')['title'].first().value_counts()\n",
    "\n",
    "review_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter movies with 5 or more reviews\n",
    "filtered_data = data.groupby('title').filter(lambda x: len(x) >= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30202"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roberta model exploration\n",
    "- https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment\n",
    "- https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment\n",
    "- https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison: Pretrained Language Model(Roberta) vs. NLTK\n",
    "\n",
    "\n",
    "### Pretrained Language Model:\n",
    "The `twitter-xlm-roberta-base-sentiment` model is a transformer-based model fine-tuned for sentiment analysis on a multilingual dataset (specifically, tweets). It can capture more nuanced meanings, slang, and contextual variations, especially in different languages or on social media.\n",
    "\n",
    "In contrast, **TextBlob** is a lexicon-based approach. It uses predefined word sentiment scores to determine sentiment, which can sometimes fail to capture context, irony, or more complex sentence structures.\n",
    "\n",
    "### Deep Learning vs. Lexicon-Based:\n",
    "Transformer models like **XLM-RoBERTa** learn from vast amounts of data and fine-tuned tasks, allowing them to generalize better for different types of text. This leads to more accurate sentiment predictions, especially in real-world use cases.\n",
    "\n",
    "TextBlob, based on **nltk**, is more rule-based and not as flexible. Its sentiment analysis works well for simpler sentences, but it may struggle with sarcasm, negation, or idiomatic expressions.\n",
    "\n",
    "### Multilingual Capability:\n",
    "The `twitter-xlm-roberta-base-sentiment` model is multilingual, designed to understand and analyze sentiment in many languages.\n",
    "\n",
    "TextBlob primarily works in English, limiting its usefulness for non-English data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoConfig\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load tokenizer and model\n",
    "\n",
    "\n",
    "MODEL = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Batch size for processing\n",
    "batch_size = 16\n",
    "\n",
    "# Function to predict sentiment for a batch of feedback\n",
    "def predict_sentiment_batch(feedbacks):\n",
    "    # Tokenize the input batch\n",
    "    encoded_feedbacks = tokenizer(feedbacks, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Predict sentiment with no gradient calculation (for inference)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoded_feedbacks)\n",
    "    \n",
    "    # Extract sentiment scores and apply softmax to get probabilities\n",
    "    scores = outputs.logits.detach().numpy()\n",
    "    sentiments = []\n",
    "    for score in scores:\n",
    "        score = softmax(score, axis=-1)\n",
    "        sentiment_labels = ['rotten', 'neutral', 'ripe']  \n",
    "        sentiments.append(sentiment_labels[score.argmax()])  \n",
    "    return sentiments\n",
    "\n",
    "# Ensure the 'sentiment' column is created with the same size as 'review'\n",
    "filtered_data['sentiment'] = None\n",
    "\n",
    "# Batch processing the feedbacks to predict sentiments\n",
    "for i in range(0, len(filtered_data), batch_size):\n",
    "    feedback_batch = filtered_data['review'].iloc[i:i+batch_size].tolist()\n",
    "    sentiments = predict_sentiment_batch(feedback_batch)\n",
    "    \n",
    "    # Assign the predicted sentiments back to the 'sentiment' column\n",
    "    filtered_data.loc[i:i+batch_size-1, 'sentiment'] = sentiments\n",
    "\n",
    "# Check the results\n",
    "print(filtered_data[['review', 'sentiment']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
